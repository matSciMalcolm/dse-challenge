{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Models\n",
    "When choosing the correct machine learning it is necessary to explore changes in the data and there effect on the models accuracy metrics. This notebook facilitates running 10-fold group cross validation on different types of models in parallel to assist in choosing the correct model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#### Standard Libraries ####\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import timeit\n",
    "\n",
    "#### Third-party Libraries ####\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier as SRC\n",
    "from lolopy.learners import RandomForestClassifier as LRC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#### Local Libraries ####\n",
    "from utils.utils import (Result, run_k_folds, \n",
    "                   report_column_labels,\n",
    "                   compile_data, oversample)\n",
    "from utils.data_manager import DataManager\n",
    "from utils.featurizer import Featurizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "Use this cell to set any necessary parameters.\n",
    "* `np.random.seed()` Set the random seed of the notebook for reproducibility.\n",
    "* `load_path` Path to training data.\n",
    "* `save_path` Where to save the results of cross validation.\n",
    "* `mp_api_key_path` Path to a `.txt` file containing a [Materials Project](https://materialsproject.org/) API key.\n",
    "* `oversample` Fix class imbalance by super sampling the minority class\n",
    "* `data_ramp` Run cross validation sequentially on even divisions of the training data. Used to investigate impact of additional training data.\n",
    "* `feature_set` A list of key-words from 'standard', 'cmpd_energy', 'energy_a', or 'energy_b' that sets which [MatMiner](https://hackingmaterials.lbl.gov/matminer/) composition features to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "np.random.seed(8)\n",
    "load_path = os.path.join('..','data','training_data.csv')\n",
    "save_path = os.path.join('..','results','final_testing.csv')\n",
    "mp_api_key_path = os.path.join('..','configuration','mp_api_key.txt')\n",
    "oversample = True\n",
    "data_ramp = False\n",
    "feature_set = ['standard']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The `DataManager` handles loading and storing training data from a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Loaded 2572 records.'\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "with open(mp_api_key_path, 'r') as f:\n",
    "    mp_api_key = f.readline().rstrip()\n",
    "dm = DataManager(load_path, save_path)\n",
    "dm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `DataManager` to sample from the data to improve the speed of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "if not data_ramp:\n",
    "    dm.sample_data(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting and Converting Training Data\n",
    "The `DataManager` class provides several useful methods for facilitating the transformation of the native training data to the binary classifier schema.\n",
    "* `to_binary_classes()` will convert the formula and output columns of the data attribute series of binary compounds which represent the stability vector.\n",
    "* `get_pymatgen_composition()` will convert formulas to pymatgen `Composition` objects which work with MatMiner's composition featurizers.\n",
    "* `remove_noble_gasses()` will remove any noble gases which we know to be unstable when combined with other elements.\n",
    "* `remove_features()` strips out the pre-featurized data provided. We have checked and the features provided are identical to the 'standard' feature set here (stoichiometric norms and magpie elemental features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format and careate composition objects\n",
    "dm.to_binary_classes()\n",
    "dm.get_pymatgen_composition()\n",
    "dm.remove_noble_gasses()\n",
    "dm.remove_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling to accomodate the data ramp feature\n",
    "if data_ramp:\n",
    "    dm.data = dm.data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Featurizer` class will assist you in applying sets of MatMiner composition features to your training data. If you wish to use the energy features you must supply a valid Materials Project api key. Featurization cant take up to 30 min when using energy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Featurizer(feature_set, mp_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b57a9ce7ed34f86842097d862d00d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MultipleFeaturizer', max=871, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dm.featurized_data = f.featurize(dm.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the process of converting the data to the binary classification scheme we labeled each chemical system (formulaA, formulaB pair) with a unique number. Doing so allows us to group together integer formulas from the same system and ensure that they do not become split across the training and testing set during cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set group labels for group K-folds\n",
    "dm.groups = dm.data['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training labels\n",
    "dm.outputs = dm.data['stable']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "Cross validation is a technique for assessing model accuracy. Here we provide the `run_k_folds` function to help with running complex group k-folds cross validation with or without super sampling or data ramping. Further it is designed to be used on multiple models at once allowing the efficient evaluation of many types of models in the search for the best fit to the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure group K-folds\n",
    "k_folds = partial(run_k_folds, inputs=dm.featurized_data,\n",
    "                  outputs=dm.outputs, groups=dm.groups,\n",
    "                  sampling=oversample, ramp=data_ramp, splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set which models we want to run cross validation on by passing a list of scikit-learn style models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the models we want to run group K-folds on\n",
    "models = [GaussianNB(), SVC(), SRC(), LogisticRegression(), DummyClassifier(strategy=\"most_frequent\")]\n",
    "#models = [SRC()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model's cross validation is assigned a core on the CPU so that evaluation happens in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning:\n",
      "\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n",
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up workers for each job\n",
    "pool = mp.Pool(processes=mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "start_time = timeit.default_timer()\n",
    "results = pool.map(k_folds, models)    \n",
    "elapsed = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are stored in a csv file and can be analyzed in notebook 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>data_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>871</td>\n",
       "      <td>0.759450</td>\n",
       "      <td>0.094639</td>\n",
       "      <td>0.439760</td>\n",
       "      <td>0.073688</td>\n",
       "      <td>0.550386</td>\n",
       "      <td>0.136503</td>\n",
       "      <td>0.401819</td>\n",
       "      <td>0.130783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>871</td>\n",
       "      <td>0.833208</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>871</td>\n",
       "      <td>0.904609</td>\n",
       "      <td>0.023350</td>\n",
       "      <td>0.663163</td>\n",
       "      <td>0.070201</td>\n",
       "      <td>0.572087</td>\n",
       "      <td>0.112946</td>\n",
       "      <td>0.816171</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>871</td>\n",
       "      <td>0.827673</td>\n",
       "      <td>0.063149</td>\n",
       "      <td>0.614310</td>\n",
       "      <td>0.094820</td>\n",
       "      <td>0.779972</td>\n",
       "      <td>0.077787</td>\n",
       "      <td>0.519593</td>\n",
       "      <td>0.131976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>871</td>\n",
       "      <td>0.833208</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     type  data_size  accuracy  accuracy_std        f1    f1_std    recall  recall_std  precision  precision_std\n",
       "0              GaussianNB        871  0.759450      0.094639  0.439760  0.073688  0.550386    0.136503   0.401819       0.130783\n",
       "1                     SVC        871  0.833208      0.030400  0.000000  0.000000  0.000000    0.000000   0.000000       0.000000\n",
       "2  RandomForestClassifier        871  0.904609      0.023350  0.663163  0.070201  0.572087    0.112946   0.816171       0.113099\n",
       "3      LogisticRegression        871  0.827673      0.063149  0.614310  0.094820  0.779972    0.077787   0.519593       0.131976\n",
       "4         DummyClassifier        871  0.833208      0.030400  0.000000  0.000000  0.000000    0.000000   0.000000       0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled = []\n",
    "for result in results:\n",
    "    compiled.extend(compile_data(result))\n",
    "res_df = pd.DataFrame(compiled, columns=report_column_labels)\n",
    "res_df.to_csv(save_path)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Single Model\n",
    "The below code is used to fit a single model to all of the training data. It also allows you to export the model as a pickle for use with other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "model_export_path = os.path.join('..','models','model.sav')\n",
    "\n",
    "# Choose which model from the list used for K-folds\n",
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply oversampling to the training data\n",
    "train = oversample(np.arange(0,len(dm.featurized_data),1), dm.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/malcolmdavidson/anaconda3/envs/tecca/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(dm.featurized_data[train], dm.outputs[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and export the model\n",
    "import pickle\n",
    "pickle.dump(model, open(model_export_path, 'wb+'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
