{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evauation\n",
    "Classification models need the following metrics\n",
    "\n",
    "Cross Validation\n",
    "- Accuracy\n",
    "- error\n",
    "\n",
    "ROC Curve\n",
    "Steps\n",
    "- load data\n",
    "- featurize\n",
    "- choose model\n",
    "- pass data and HP's\n",
    "- run CV\n",
    "- ROC possible?\n",
    "- tabulate results\n",
    "- report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Standard Libraries ####\n",
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "import timeit\n",
    "import uuid\n",
    "\n",
    "#### third-party Libraries ####\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier as SRC\n",
    "from lolopy.learners import RandomForestClassifier as LRC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#### Local Libraries ####\n",
    "from utils import (Result, run_k_folds, \n",
    "                   report_column_labels,\n",
    "                   compile_data)\n",
    "from data_manager import DataManager\n",
    "from featurizer import Featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "np.random.seed(8)\n",
    "load_path = os.path.join('data','training_data.csv')\n",
    "save_path = os.path.join('results','baseline_fixed_sample.csv')\n",
    "mp_api_key = '7n6DwPUQ5cf8ZTWO'\n",
    "oversample = False\n",
    "data_ramp = True\n",
    "feature_set = ['standard']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "This object should handle data load and sampling.\n",
    "\n",
    "Should be able to do the following:\n",
    "1. load and sample \n",
    "2. Run a data ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Loaded 2572 records.'\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "dm = DataManager(load_path, save_path)\n",
    "dm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "if not data_ramp:\n",
    "    dm.sample_data(100)\n",
    "    #dm.data.to_csv('data/sample_07_19_19.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format and careate composition objects\n",
    "#dm.compute_formula()\n",
    "dm.to_binary_classes()\n",
    "dm.get_pymatgen_composition()\n",
    "dm.remove_noble_gasses()\n",
    "dm.remove_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_ramp:\n",
    "    dm.data = dm.data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Featurizer(feature_set, mp_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e972aadbc04be89e750f311db57529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='MultipleFeaturizer', max=20570, style=ProgressStyle(descriptiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dm.featurized_data = f.featurize(dm.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.groups = dm.data['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training labels\n",
    "dm.outputs = dm.data['stable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = partial(run_k_folds, inputs=dm.featurized_data, outputs=dm.outputs, groups=dm.groups, sampling=oversample, ramp=data_ramp, splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set models\n",
    "models = [GaussianNB(), SVC(), SRC(), LogisticRegression(), DummyClassifier(strategy=\"most_frequent\")]\n",
    "#models = [SRC()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pool = mp.Pool(processes=mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "start_time = timeit.default_timer()\n",
    "results = pool.map(k_folds, models)    \n",
    "elapsed = timeit.default_timer() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>data_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_std</th>\n",
       "      <th>f1</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>recall</th>\n",
       "      <th>recall_std</th>\n",
       "      <th>precision</th>\n",
       "      <th>precision_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.770057</td>\n",
       "      <td>0.019601</td>\n",
       "      <td>0.392930</td>\n",
       "      <td>0.039705</td>\n",
       "      <td>0.595923</td>\n",
       "      <td>0.047151</td>\n",
       "      <td>0.294117</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>8228</td>\n",
       "      <td>0.745751</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>0.389440</td>\n",
       "      <td>0.026976</td>\n",
       "      <td>0.643349</td>\n",
       "      <td>0.033973</td>\n",
       "      <td>0.280196</td>\n",
       "      <td>0.026962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>12342</td>\n",
       "      <td>0.749066</td>\n",
       "      <td>0.014398</td>\n",
       "      <td>0.389991</td>\n",
       "      <td>0.031893</td>\n",
       "      <td>0.639151</td>\n",
       "      <td>0.041356</td>\n",
       "      <td>0.281067</td>\n",
       "      <td>0.027180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>16456</td>\n",
       "      <td>0.743926</td>\n",
       "      <td>0.015175</td>\n",
       "      <td>0.389613</td>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.651367</td>\n",
       "      <td>0.063375</td>\n",
       "      <td>0.278905</td>\n",
       "      <td>0.023668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>20570</td>\n",
       "      <td>0.748274</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>0.391613</td>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.648737</td>\n",
       "      <td>0.049388</td>\n",
       "      <td>0.280810</td>\n",
       "      <td>0.016082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.875064</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>8228</td>\n",
       "      <td>0.874091</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>12342</td>\n",
       "      <td>0.874333</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC</td>\n",
       "      <td>16456</td>\n",
       "      <td>0.873605</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>20570</td>\n",
       "      <td>0.875061</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.885026</td>\n",
       "      <td>0.013493</td>\n",
       "      <td>0.339805</td>\n",
       "      <td>0.080845</td>\n",
       "      <td>0.241103</td>\n",
       "      <td>0.067493</td>\n",
       "      <td>0.595326</td>\n",
       "      <td>0.087391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>8228</td>\n",
       "      <td>0.894021</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>0.418375</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>0.303538</td>\n",
       "      <td>0.045671</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>0.099266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>12342</td>\n",
       "      <td>0.899531</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.470906</td>\n",
       "      <td>0.041551</td>\n",
       "      <td>0.357821</td>\n",
       "      <td>0.044030</td>\n",
       "      <td>0.695163</td>\n",
       "      <td>0.050716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>16456</td>\n",
       "      <td>0.901072</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.488711</td>\n",
       "      <td>0.041123</td>\n",
       "      <td>0.376878</td>\n",
       "      <td>0.043273</td>\n",
       "      <td>0.701775</td>\n",
       "      <td>0.049944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>20570</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.520811</td>\n",
       "      <td>0.030173</td>\n",
       "      <td>0.409357</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>0.716911</td>\n",
       "      <td>0.038684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.875051</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>0.224917</td>\n",
       "      <td>0.079280</td>\n",
       "      <td>0.145744</td>\n",
       "      <td>0.052358</td>\n",
       "      <td>0.524441</td>\n",
       "      <td>0.185808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>8228</td>\n",
       "      <td>0.877859</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.224078</td>\n",
       "      <td>0.065703</td>\n",
       "      <td>0.142123</td>\n",
       "      <td>0.047602</td>\n",
       "      <td>0.564219</td>\n",
       "      <td>0.127869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>12342</td>\n",
       "      <td>0.879356</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.222804</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>0.137414</td>\n",
       "      <td>0.018254</td>\n",
       "      <td>0.599475</td>\n",
       "      <td>0.140652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>16456</td>\n",
       "      <td>0.879013</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>0.218082</td>\n",
       "      <td>0.033970</td>\n",
       "      <td>0.134578</td>\n",
       "      <td>0.026570</td>\n",
       "      <td>0.600921</td>\n",
       "      <td>0.066994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>20570</td>\n",
       "      <td>0.879874</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.207990</td>\n",
       "      <td>0.038336</td>\n",
       "      <td>0.126623</td>\n",
       "      <td>0.024877</td>\n",
       "      <td>0.587697</td>\n",
       "      <td>0.089299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>4114</td>\n",
       "      <td>0.875064</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>8228</td>\n",
       "      <td>0.874091</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>12342</td>\n",
       "      <td>0.874333</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>16456</td>\n",
       "      <td>0.873605</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>20570</td>\n",
       "      <td>0.875061</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      type  data_size  accuracy  accuracy_std        f1  \\\n",
       "0               GaussianNB       4114  0.770057      0.019601  0.392930   \n",
       "1               GaussianNB       8228  0.745751      0.025916  0.389440   \n",
       "2               GaussianNB      12342  0.749066      0.014398  0.389991   \n",
       "3               GaussianNB      16456  0.743926      0.015175  0.389613   \n",
       "4               GaussianNB      20570  0.748274      0.014339  0.391613   \n",
       "5                      SVC       4114  0.875064      0.011776  0.000000   \n",
       "6                      SVC       8228  0.874091      0.011641  0.000000   \n",
       "7                      SVC      12342  0.874333      0.009260  0.000000   \n",
       "8                      SVC      16456  0.873605      0.013831  0.000000   \n",
       "9                      SVC      20570  0.875061      0.002801  0.000000   \n",
       "10  RandomForestClassifier       4114  0.885026      0.013493  0.339805   \n",
       "11  RandomForestClassifier       8228  0.894021      0.013512  0.418375   \n",
       "12  RandomForestClassifier      12342  0.899531      0.008005  0.470906   \n",
       "13  RandomForestClassifier      16456  0.901072      0.009648  0.488711   \n",
       "14  RandomForestClassifier      20570  0.906077      0.003324  0.520811   \n",
       "15      LogisticRegression       4114  0.875051      0.015482  0.224917   \n",
       "16      LogisticRegression       8228  0.877859      0.013509  0.224078   \n",
       "17      LogisticRegression      12342  0.879356      0.010374  0.222804   \n",
       "18      LogisticRegression      16456  0.879013      0.012474  0.218082   \n",
       "19      LogisticRegression      20570  0.879874      0.004006  0.207990   \n",
       "20         DummyClassifier       4114  0.875064      0.011776  0.000000   \n",
       "21         DummyClassifier       8228  0.874091      0.011641  0.000000   \n",
       "22         DummyClassifier      12342  0.874333      0.009260  0.000000   \n",
       "23         DummyClassifier      16456  0.873605      0.013831  0.000000   \n",
       "24         DummyClassifier      20570  0.875061      0.002801  0.000000   \n",
       "\n",
       "      f1_std    recall  recall_std  precision  precision_std  \n",
       "0   0.039705  0.595923    0.047151   0.294117       0.037515  \n",
       "1   0.026976  0.643349    0.033973   0.280196       0.026962  \n",
       "2   0.031893  0.639151    0.041356   0.281067       0.027180  \n",
       "3   0.028700  0.651367    0.063375   0.278905       0.023668  \n",
       "4   0.021730  0.648737    0.049388   0.280810       0.016082  \n",
       "5   0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "6   0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "7   0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "8   0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "9   0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "10  0.080845  0.241103    0.067493   0.595326       0.087391  \n",
       "11  0.055203  0.303538    0.045671   0.684200       0.099266  \n",
       "12  0.041551  0.357821    0.044030   0.695163       0.050716  \n",
       "13  0.041123  0.376878    0.043273   0.701775       0.049944  \n",
       "14  0.030173  0.409357    0.028394   0.716911       0.038684  \n",
       "15  0.079280  0.145744    0.052358   0.524441       0.185808  \n",
       "16  0.065703  0.142123    0.047602   0.564219       0.127869  \n",
       "17  0.032489  0.137414    0.018254   0.599475       0.140652  \n",
       "18  0.033970  0.134578    0.026570   0.600921       0.066994  \n",
       "19  0.038336  0.126623    0.024877   0.587697       0.089299  \n",
       "20  0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "21  0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "22  0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "23  0.000000  0.000000    0.000000   0.000000       0.000000  \n",
       "24  0.000000  0.000000    0.000000   0.000000       0.000000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled = []\n",
    "for result in results:\n",
    "    compiled.extend(compile_data(result))\n",
    "res_df = pd.DataFrame(compiled, columns=report_column_labels)\n",
    "res_df.to_csv(save_path)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "\n",
    "def local_oversample(train, outputs):\n",
    "    majority_class, minority_class = Counter(outputs[train]).most_common()\n",
    "    minority = train[numpy.where(outputs[train] == minority_class[0])[0]]\n",
    "    majority = train[numpy.where(outputs[train] == majority_class[0])[0]]\n",
    "    minority_upsampled = resample(minority,\n",
    "                              replace=True,\n",
    "                              n_samples=len(majority),\n",
    "                              random_state=8)\n",
    "    t = numpy.append(majority, minority_upsampled)\n",
    "    pprint(len(t))\n",
    "    return (t, minority, majority, minority_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRC()\n",
    "ovs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold, GroupKFold, LeavePGroupsOut, LeaveOneGroupOut\n",
    "inputs = dm.featurized_data\n",
    "outputs = dm.outputs\n",
    "groups = dm.groups\n",
    "gkf = GroupKFold(n_splits=10)\n",
    "lpgo = LeavePGroupsOut(n_groups=1)\n",
    "logo = LeaveOneGroupOut()\n",
    "splits = list(gkf.split(inputs, outputs, groups=groups.values))\n",
    "#splits = list(logo.split(inputs, outputs, groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = splits[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Place all data into df's for easy analysis\n",
    "train_df = pandas.DataFrame(dm.data.ix[train, ['formula','group','stable']])\n",
    "test_df = pandas.DataFrame(dm.data.ix[test, ['formula','group','stable']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ovs:\n",
    "    train, minority, majority, minority_upsampled = local_oversample(train, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdavidson/.conda/envs/tecca/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning:\n",
      "\n",
      "The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the ML\n",
    "model.fit(inputs[train], outputs[train])\n",
    "prediction = model.predict(inputs[test])\n",
    "acc = accuracy_score(outputs[test], prediction)\n",
    "f1s = [precision_recall_fscore_support(\n",
    "    outputs[test], prediction, labels=[0,1], average='binary')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18513"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Place all data into df's for easy analysis\n",
    "train_df = pandas.DataFrame(dm.data.ix[train, ['formula','group','stable']])\n",
    "test_df = pandas.DataFrame(dm.data.ix[test, ['formula','group','stable']])\n",
    "pred_df = pandas.DataFrame(dm.data.ix[test, ['formula','group','stable']])\n",
    "pred_df['prediction'] = prediction\n",
    "acc_df = pandas.DataFrame([acc], columns=['accuracy'])\n",
    "\n",
    "f1_df = pandas.DataFrame(\n",
    "        f1s, columns=['precision', 'recall', 'f1', 'support'])\n",
    "ov_df = pd.DataFrame([train_df['group'].isin(test_df['group']).any()], columns=['overlap'])\n",
    "\n",
    "try:\n",
    "    lab_df = pandas.DataFrame([pred_df['prediction'].value_counts().values], columns=['pred_0','pred_1'])\n",
    "except:\n",
    "    lab_df = pandas.DataFrame([pred_df['prediction'].value_counts().values], columns=['pred_0'])\n",
    "if ovs:\n",
    "    sample_df = pandas.DataFrame([train_df['stable'].value_counts().values], columns=['smpl_0','smpl_1'])\n",
    "else:\n",
    "    sample_df = pandas.DataFrame([], columns=['sample'])\n",
    "# Get the accuracy for each label\n",
    "#ac_lab_df = pandas.DataFrame([test_df['stable'].value_counts().values], columns=['acc_0','acc_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = f1_df.join(acc_df).join(ov_df).join(lab_df).join(ac_lab_df).join(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = f1_df.join(acc_df).join(ov_df).join(lab_df).join(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res.to_csv('results/final_modle.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>overlap</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.715232</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>None</td>\n",
       "      <td>0.904716</td>\n",
       "      <td>False</td>\n",
       "      <td>1906</td>\n",
       "      <td>151</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall        f1 support  accuracy  overlap  pred_0  pred_1  \\\n",
       "0   0.715232  0.413793  0.524272    None  0.904716    False    1906     151   \n",
       "\n",
       "  sample  \n",
       "0    NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#pickle.dump(model, open('rfc.sav', 'wb+'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
